---
title: "Investigating Vocational Teachers' Informal Workplace Learning Using Experience Sampling"
author: "Manuel Böhm"
date: '`r Sys.Date()`'
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    keep_tex: TRUE
  word_document: default
  html_document:
    toc: true
    toc_depth: '2'
    df_print: paged
bibliography:
- _bib/references.bib
- _bib/grateful-refs.bib
csl: _bib/apa.csl
link-citations: true
toc: true
toc-title: Article Outline
header-includes: \pagenumbering{gobble}
numbersections: true
---

\newpage
\pagenumbering{arabic}

# Acknowledgement {.unnumbered}

We would like to express our gratitude to Miss Julia Banschbach for the invaluable work in her masters' thesis. The created  learning outcome framework based on the literature as well as her qualitative data analysis served as a basis for answering the second research question in this paper. 

\newpage

# Abstract {.unnumbered}

...

Keywords: workplace learning, teacher training, informal learning, experience sampling, multilevel modelling

\newpage

# Introduction

[Schools as learning venues for teachers in the sense of workplace learning]
While schools are learning venues for teachers, they also are teachers' workplaces (https://www.tandfonline.com/doi/epdf/10.1080/0158037X.2024.2314128?needAccess=true) and therefore serve as context for teachers' workplace learning (Billett, 2001; workplace affordances, ...). 

[highlighted under todays' current conditions]

[Importance and relevance of professional learning]

[Comparison informal and formal workplace learning]


Professional learning is 

According to @rauschUsingDiariesResearch2014, ...

-   teacher shortage and difficult working conditions of teachers

    -   stress, coping are important

    -   learning of teachers has a particular important role

        -   teachers have to prepare their lessons and

        -   furthermore, teachers need to stay up to date

        -   The teaching profession has a particular set of characteristics and job demands. At the same time, teachers are provided with a high degree of freedom or job decision latitude. –\> Karasek: learning hypothesis

    -   vocational schools are under-represented in studies (). while there is research tackling other schools, still very little research on vocational schools.

-   lack of research on teachers at vocational schools ()

    -   experience sampling

In @@boehmWorkingHoursWork2024, results from the study were described with a focus on teachers' working hours and the distribution of working hours between different tasks. 
Building on this article, this paper will focus on teachers' workplace learning. 
Thus, the following research questions will be tackled:

1.  RQ (Stress, coping and learning across activities, control for age, sex, jobscope + data from the questionnaire study) - MLM

    Which of teachers' daily work activities are perceived as (a) the most stressful and (b) with which of the stressful activities could the teachers cope the best? (c) Which of teachers' daily activities are perceived as the most conducive to learning?

2.  [Description of the Learning (freetext fields, qualitative analysis)]

3.  RQ (Karasek, control for age, sex, jobscope + data from the questionnaire study) - MLM

    Do stress and coping predict informal learning in teachers' daily work activities, as stated in Karasek's learning hypothesis?

    H: according to Karasek

include a participation effect (control for a bias) H: higher participation -\> bigger pc_learn Can time effects be found in the data? Does continued experience sampling have an effect on perceived informal learning?

# Research on Teachers' Workplace Learning

## Characteristics of the Teaching Profession and Vocational Teachers' Daily Work Activities

### Characteristics

-   High degree of freedom in the profession

-   subject (especially in vocational schools).

    -   --\> high demand to learn

-   Needed: Alternative to Rothland (2013)???

    -   Multiple sources that describe the characteristics

-   teacher stressors and coping (briefly): outline from research on teacher stress

    -   –\> Lazarus & Folkman (for Stress)

### Teachers' Daily Work Activities

-   Overview teachers' work activities (framework from the literature)

## Workplace Learning and Vocational Teachers' Learning Activities

-   formal, non-formal vs. informal WPL (so far from bwpat!!!)
- how do teachers learn?
- include selected frameworks from literature (NK, MA)

In workplace learning, researchers typically differentiate between formal, non-formal and informal learning (e.g., Coombs & Ahmed, 1974; Imants & van Veen, 2010). Formal learning is typically defined as structured learning in pedagogical settings such as university teacher training. In these settings, learning occurs intentionally and is planned (Marsick & Watkins, 2015; UNESCO Institute for Statistics, 2012). Non-formal learning is “institutionalized, intentional and planned” as well (UNESCO Institute for Statistics, 2012, p. 11) but in contrast to formal learning, it is not part of the national qualifications framework but includes training and development in companies (Bilger et al., 2013, p. 20) such as information resources for further teacher training. In contrast, informal learning is unintentional and experiential. It occurs as a by-product of other activities such as working (e.g., Marsick & Watkins, 2015, p. 6; UNESCO Institute for Statistics, 2012, p. 19). This learning is also referred to as implicit learning (Eraut, 2004) or incidental learning (Marsick & Watkins, 2015). Though less conscious, this informal learning is considered as a vital source of teachers’ professional development. Work task characteristics that foster informal workplace learning include newness, complexity, collaboration and so forth (Hoekstra, 2007; Lohman, 2003; Rausch, 2013; Kwakman, 2003) many of which, as discussed above, are also likely to cause stress (Karasek, 1979).

-   Billett?!
-   Karasek
    -   Studies on Karasek
        -   The Job Demand-Control (-Support) Model and psychological well-being: A review of 20 years of empirical research (<https://doi.org/10.1080/026783799296084>)
        -   

1.  Billett and others (which characteristics of the situation and the activity foster learning?!)

2.  Consideration of stress (Karasek, ...)

    use stress as a characteristic of activities to introduce Karasek (and briefly talk about negative consequences: Lazarus & Folkman)

get concrete: Teachers' Learning Activities

## Learning Outomes from Vocational Teachers' Workplace Learning

-   Goal: categorizing learning outcomes that stem from teachers' informal workplace learning
-   For this, existing frameworks from workplace learning literature are analyzed and compared
-   Then, a category framework is developed deductively from existing frameworks and then adjusted inductively from the results from this study.

### Eraut (2004)

8 categories:

-   

-   

### Tynjälä (2013, 3-P model)

### Kyndt et al. (2013)

### Cerasoli et al. (2018)

### Park (2020)

### Smet et al. (2022)

--\> also consider additional frameworks from teacher professional development

## Job Demands and Job Resources in the Teaching Profession

### Job Demands / Stress

### Job Resources / Coping

### The Effect of Job Demands / Stress and Job Resources / Coping on Vocational Teachers' Workplace Learning

# Description of the Longitudinal Study

## Research Design and Sample (1 = M, 0 = W)

This study is part of a research programme (AARL-BS) which was initiated to investigate the relations between working hours, work activities, and work experience, such as learning, stress and coping of teachers at vocational schools. [Data was collected in two studies, an online survey study and an app-based diary study. This allowed for balancing the advantages and disadvantages of the respective methods regarding the estimation of working hours and the measuring of work experience, in particular. Participation was voluntary and all participants provided written informed consent.]{.underline}

### Questionnaire Study

The survey study was conducted from February to November 2022. A sample of 1,146 full-time teachers participated in the survey study, 74.3 % of which held no further management function beyond their teaching duties. The mean age was 46.98 years and 39.1 % of the sample is female. The distribution of the survey sample is representative for vocational teachers in the German federal state of Baden-Wuerttemberg with regard to gender, age composition, level of employment, and administrative district.

In the survey study, data on teachers’ working time, the distribution of the working hours between different tasks, working conditions, job satisfaction, and further constructs were collected. The questionnaire was developed on the basis of a comprehensive literature review (Aprea & Sarochan, 2023) and intensive consultations with representatives of the Association of Vocational School Teachers in Baden-Württemberg (BLV). [See the other papers ...]{.underline}

### Diary Study (go more into detail here, ESM, design)

The diary study took place from mid-March to mid-October 2022, including weekends and vacation periods, excluding four weeks during the summer holiday. A multi-cohort design was chosen to reduce participant burden. Each of the five cohorts held the diary for one week and paused for four weeks. The diary app was implemented using mQuest by the German online service provider Cluetec (Karlsruhe). [Diary entries from 145 full-time teachers were included, 75.2 % of which without a management function. The mean age is 44.99 years and 46.9 % of the sample is female. After intensive data preparation and filtering, the analysis is based on 10.327 activities that were reported in the diary app]{.underline}.

The participants were requested to record all work-related activities by selecting the respective work activity from a given list of activities, indicating start and end time and answering one item each for experienced stress, coping, and learning related to the respective task. [In addition, in a weekly review, the participants were requested to indicate the working hours for each day of the past week.]{.underline} During a cohort’s diary period, three daily notifications reminded the participants to record their work activities.

## Measures and Data Analysis

-   Stress, Coping and Learning across the Daily Work Activities
    -   Stress, coping and learning were all measured using 1 item scales self report
    -   Description of the Developed Task Framework

From bwpat

Afterwards, the perception of stress, coping and learning at the given work activity are evaluated by the participants. (1) Stress, (2) coping and (3) learning are each designed with an 8-point Likert-scale with 0 as the lowest and 7 as the highest value. To avoid influencing entries with a default value, “-1” is set as the default value in these three items and must be changed to proceed. All three questions are depicted with a slider to set the value and a brief explanation: (1) Did you find this work activity stressful? (0 = not at all stressful; 7 = very stressful; -1 = invalid entry); (2) How well were you able to cope with this stress? (0 = not coped well at all; 7 = coped very well; -1 = invalid entry); (3) Did you learn anything new for your job during this work activity? (0 = learned nothing at all; 7 = learned very much; -1 = invalid entry). Based on theoretical assumptions, participants could only evaluate their coping for work activities with a stress-level above 0.

### Learning Outcome Framework (RQ 2)

K. Kompetenzebene

KI. Individuum

Performanzebene

## Data Analysis (still from bwpat)

Descriptive statistics were calculated to address RQ1 and RQ2. Regarding RQ3, a multiple level model was calculated to investigate the statistical prediction of vocational teachers' informal learning based on their stress and coping during their daily work activities, following Karasek's learning hypothesis. *Interaction terms were checked. However, moderators showed no significant effects, so no interactions were included in the final analysis.*

```{r}
# if any objects are available in the global environment, remove them
rm(list = ls())

```


```{r maintenance, eval=FALSE, include=FALSE}
source("_src/maintenance.R", local = knitr::knit_global())
```

```{r session start, include=FALSE}
## Load and install packages (using package manager)
if (!require("pacman")) {
  install.packages("pacman")
  library(pacman)
}
pacman::p_load(papaja, knitr, dplyr, remotes, lme4, tidyr, kableExtra,
               modelsummary, performance, stats, lmerTest, ggplot2, corrr,
               parameters, car, psych, jtools, grateful, blockTools,
               robustlmm, usethis, gitcreds, stringr, HLMdiag, lmtest, effects, 
               sjPlot, devtools, rmdwc, fastDummies, crosstable, fuzzyjoin, datawizard, forcats) 

# install.packages("robustlmm", dependencies = TRUE)
# install.packages("broom.mixed", dependencies = TRUE)

```

```{r load files, include=FALSE}
# welcome questionnaire
welcome_raw <- read.csv2("_data/raw/20221018_1718_1_AARL-BS Willkommen.csv")
# activities questionnaire
activities_raw <- read.csv2("_data/raw/20221018_1717_2_AARL-BS Taetigkeiten_de102944944440141306.csv")
# jobscope
jobscope <- read.csv2("_data/jobscope.csv", na = "?")
# jobscope correction
jobscope_correction <- read.csv2("_data/jobscope_v3.csv")
# learning outcome framework
lo_categorization <- read.csv2("_data/lo_categorization_cat_1_only.csv")
lo_categorization <- lo_categorization %>%
  select(-pc_learn)

lo_categorization <- lo_categorization %>%
  distinct(, .keep_all = TRUE)

# parent categories for lo_framework
lo_framework <- read.csv2("_archive/framework_learning_outcomes.csv")

lo_framework <- lo_framework %>%
  mutate(across(everything(), tolower))

# zuordnung_new_task with activity names (12, 29, 3)
zuordnung_new_task <- read.csv2("_data/zuordnung_new_task_.csv")

```

```{r data prep, include=FALSE}
source("_src/data_prep_welcome.R", local = knitr::knit_global())
source("_src/data_prep_activities.R", local = knitr::knit_global())
source("_src/data_prep_qualitative.R", local = knitr::knit_global())

#####
### format all datatypes appropriately! (see previous code (data_prep)) #####
#####
```

```{r prepare combined_df with values from data_prep_qual & format data, include=FALSE}
# import into combined_df from df: task_no, task, sex, age, jobscope, duration
# combined_df$age <- welcome$age[match(combined_df$code, welcome$code)] #####

# update selected values in with values from df (manual data_prep)
# values: age, sex, jobscope, act_no, activity, duration

# Define your list of column names
# list <- c("age", "sex", "jobscope", "act_no", "activity", "duration")
list <- c("age", "sex", "jobscope", "act_no", "activity")
list_code <- c("age", "sex", "jobscope")
list_id <- c("act_no", "activity")

for (value in list_code) {
# Step 1
combined_df[[paste0(value, "_df")]] <- df[[value]][match(combined_df$code, df$code)]
}

for (value in list_id) {
combined_df[[paste0(value, "_df")]] <- df[[value]][match(combined_df$id, df$id)]
}

# Step 2
for (value in list){
  combined_df[[value]] <- ifelse(is.na(combined_df[[paste0(value, "_df")]]) | 
                                   is.na(match(combined_df$code, df$code)), 
    combined_df[[value]],                         
    combined_df[[paste0(value, "_df")]]           
  )
}

# LOGIC #####
# step 1 (simply transfer the values, keep all values from df)
# combined_df$age_df <- df$age[match(combined_df$code, df$code)]
# combined_df$act_no_df <- df$act_no[match(combined_df$id, df$id)]
# combined_df$activity_df <- df$activity[match(combined_df$code, df$id)]

# step 2
# age <- ifelse
# - age_df = NA OR 
# - no match

# then
# = age
# else
# age_df
##################

combined_df <- combined_df %>%
  select(-age_df, -sex_df, -jobscope_df, -act_no_df, -activity_df, -category)

#####
# Adjustments of data (format, corrections, ...)
#####

# remove all other activities (29) reporting illness
# create the dataframe sickness
df_sickness <- df %>%
  filter(krank_ == 1) %>%
  select(id, code, krank_)

combined_df$sickness <- 0
combined_df$sickness <- df_sickness$krank_[match(combined_df$id, df_sickness$id)]

combined_df <- combined_df %>%
  filter(is.na(sickness))

# remove additional reportings of sickness and vacation
# sickness
combined_df <- combined_df %>%
  filter(!(str_detect(activity, "onstige") & 
           (str_detect(activity, "krank") | str_detect(activity, "Krank") | str_detect(activity, "corona") | str_detect(activity, "Corona")) &
           id != 20252 & id != 19836  & id != 48289 & id != 28568 & id != 4759))

# vacation
combined_df <- combined_df %>%
  filter(!(str_detect(activity, "urlaub") | str_detect(activity, "Urlaub")))

# school holidays 
combined_df <- combined_df %>%
  filter(!(str_detect(activity, "ferien") | str_detect(activity, "oster") | str_detect(activity, "Oster")  | str_detect(activity, "Ferien") | str_detect(activity, "schulfrei")))

# weekend
combined_df <- combined_df %>%
  filter(!str_detect(activity, "ochenende"))

# free day
combined_df <- combined_df %>%
  filter(!(str_detect(activity, "frei") | str_detect(activity, "Freien Tag") | str_detect(activity, "eiertag")))

# commuting between home and school
combined_df <- combined_df %>%
  filter(!(str_detect(activity, "rbeitsweg") | str_detect(activity, "hause") | str_detect(activity, "Hause") | str_detect(activity, "zur Schule") | str_detect(activity, "Anreise") | str_detect(activity, "Heim")))


# other invalid entries
combined_df <- combined_df %>%
  filter(!(str_detect(activity, "keine") | str_detect(activity, "Keine") | str_detect(activity, "mQuest") | str_detect(activity, "zeitstudie") | str_detect(activity, ": Hausarbeit") | id == 36469 | id == 49189 | id == 5081 | id == 4356 | id == 5417 | id == 17552))


##########
# correct categories
##########
# some of 29 belong to Aufsicht (9)
combined_df <- combined_df %>% 
  mutate(
    act_no = case_when(
      str_detect(activity, "onstige") & 
      (str_detect(activity, "lausuraufsicht") | str_detect(activity, "rüfungsaufsicht") | str_detect(activity, "ufsicht Klassenarbeit")) ~ 9,
      TRUE ~ act_no  # Behalte den Originalwert bei, wenn keine Bedingung zutrifft
    ),
    activity = case_when(
      str_detect(activity, "onstige") & 
      (str_detect(activity, "lausuraufsicht") | str_detect(activity, "rüfungsaufsicht") | str_detect(activity, "ufsicht Klassenarbeit")) ~ "Aufsicht",
      TRUE ~ activity  # Behalte den Originalwert bei, wenn keine Bedingung zutrifft
    )
  )
# auch Aufsicht: 35883


combined_df <- combined_df %>%
  mutate(act_no = case_when(str_detect(activity, "onstige Tätigkeit") ~ 29, .default = act_no))

# combined_df_test <- combined_df %>%
#  filter(act_no == 29)

# combined_df_test <- combined_df %>%
#  filter(act_no == 9)
    
# correct coping
combined_df$coping <- ifelse(combined_df$stress == 0, 0, combined_df$coping)

# format data for analyses
combined_df <- combined_df %>% # Before: 1=w, 2=m; NOW: 0=w, 1=m
  mutate(sex = case_match(sex, 1 ~ 0, 2 ~ 1)
         )

# correct error: 
# change value of column act_no to 3 for entry with id = "45771"
combined_df$act_no[combined_df$id == "45771"] <- 5

# In combined_df in column activity, delete whitespace at the beginning and end of the string
combined_df$activity <- str_trim(combined_df$activity)


# test
table(combined_df$activity)
table(combined_df$activity [combined_df$act_no == 9])
table(combined_df$activity [combined_df$act_no != 29])
table(combined_df$activity [combined_df$act_no == 20])
table(combined_df$activity [combined_df$act_no == 9])

# compare number of cases (which were deleted?!)

# check other activity (29)
#combined_df_other <- combined_df %>%
#  filter(act_no == 29)


# combined_df <- combined_df %>% # adjust act_no 29
#  mutate(act_no = ifelse(category == 4, 29, act_no))


# insert English activity names

```

```{r remove unnecessary columns and dataframes, include=FALSE}
rm(week_rv)
rm(weights_20)
rm(weights_fbs_20)
rm(jobscope)
rm(jobscope_correction)
rm(holidays)
rm(fbs_data)
rm(df_old)
```

# Results

## RQ1: Stress, Coping and Learning during Teachers' Daily Work Activities

-   same approach as in bwpat paper: simple comparison of mean values and SDs across the activities
-   numbers differ from results in bwpat article because of different sample size
-   29 activities?! --\> decision needed! or 12 activities?!

```{r filter and prepare data, include=FALSE}
df_rq1 <- combined_df
```

```{r correlations and data checks, include=FALSE}
# correlations: stress, coping, learning
cor_rq1 <- corrr::correlate(df_rq1 %>% select(stress, coping, pc_learn))

```

```{r rq1 correlations kable table, echo=FALSE}
cor_rq1 %>%
  as.matrix() %>%
  `colnames<-`(c("Term", "Stress", "Coping", "Learning")) %>%
  as.data.frame() %>%
  mutate(Term = c("Stress", "Coping", "Learning")) %>%
  kable(caption = "Correlations between Stress, Coping and Learning during Teachers' Daily Work Activities", 
        align = "lcccc", 
        digits = 2) %>%
  kable_styling(latex_options = c("HOLD_position"), 
                font_size = 9)
```

```{r rq1 analysis, include=FALSE}
# make sure coping is given only for stress above 0 and never -1
# something like this...
# df_rq3_coping <- df_rq3 %>%
#  mutate(coping = ifelse(coping < 0, 0, coping))

# act_no 29 does not exist... -> correct!

rq1_stress_coping_learn <- df_rq1 %>%
  group_by(act_no) %>%
  summarise(stress_m = mean(stress), 
            stress_sd = sd(stress), 
            stress_md = median(stress), 
            
            coping_m = mean(coping), 
            coping_sd = sd(coping), 
            coping_md = median(coping), 
            
            learn_m = mean(pc_learn), 
            learn_sd = sd(pc_learn), 
            learn_md = median(pc_learn)
            )
```

```{r, rq1 kable table, echo=FALSE, eval=FALSE}
rq1_stress_coping_learn %>%
# mutate_if(is.numeric, ~ifelse(is.na(.), " ", format(round(., 2)))) %>%
mutate(across(is.numeric & !act_no, ~ifelse(is.na(.x) , " ", sprintf("%.2f", .x)))) %>%
kable(# digits = c(1,2,2,2,2,2,2,2,2,2)
      , caption = "Descriptive Statistics regarding Stress, Coping and Learning during Teachers' Daily Work Activities", col.names = c("", "M", "SD", "Mdn", "M", "SD", "Mdn", "M", "SD", "Mdn"), align = "lccccccccc") %>%
        add_header_above(c("Activity" = 1, "Stress" = 3, "Coping" = 3, "Learning" = 3)) %>%
  kable_styling(latex_options = c("HOLD_position"), font_size = 9)
```

```{r, include=FALSE}
df_rq1b <- combined_df %>%
  select(act_no, pc_learn)

rq1b_learn <- df_rq1b %>%
  group_by(act_no) %>%
  summarise(learn_m = mean(pc_learn), 
            learn_sd = sd(pc_learn), 
            learn_md = median(pc_learn)
            )

# add new column with activity names from zuordnung_new_task, match via (act_no = alte_kategorie)
activity_name_29 <- zuordnung_new_task %>%
  select(alte_kategorie, task_name_en)


rq1b_learn <- rq1b_learn %>%
  left_join(activity_name_29, by = c("act_no" = "alte_kategorie")) %>%
  select(act_no, task_name_en, everything())

```

```{r rq1b only pc_learn, echo=FALSE}
rq1b_learn %>%
# mutate_if(is.numeric, ~ifelse(is.na(.), " ", format(round(., 2)))) %>%
mutate(across(is.numeric & !act_no, ~ifelse(is.na(.x) , " ", sprintf("%.2f", .x)))) %>%
kable(# digits = c(1,2,2,2,2,2,2,2,2,2)
      , caption = "Descriptive Statistics regarding Perceived Learning during Teachers' Daily Work Activities", col.names = c("", "", "M", "SD", "Mdn"), align = "llccc") %>%
        add_header_above(c("Activity" = 2, "Learning" = 3)) %>%
  kable_styling(latex_options = c("HOLD_position"), font_size = 9)

```

## RQ2: Description of the Learning During Teachers' Daily Work Activities

```{r, include=FALSE}
combined_df_lo <- combined_df %>%
  filter(pc_learn != 0)

# %>%
#  filter(learn_descr != "") # | other_descr != "")
```

```{r alternative to fuzzy join, include=FALSE}
# convert all strings in column learning_outcome in lo_categorization to lower case
lo_categorization <- lo_categorization %>%
  mutate(learning_outcome = tolower(learning_outcome))
# remove leading and ending whitespace in learn_descr
lo_categorization <- lo_categorization %>%
  mutate(learning_outcome = str_trim(learning_outcome))

# convert all strings in column learn_descr in df_rq2 to lower case
combined_df_lo <- combined_df_lo %>%
  mutate(learn_descr = tolower(learn_descr))
# remove leading and ending whitespace in learn_descr
combined_df_lo <- combined_df_lo %>%
  mutate(learn_descr = str_trim(learn_descr))

# remove "-" at the beginning of learn_descr if text follows
combined_df_lo <- combined_df_lo %>%
  mutate(learn_descr = str_replace(learn_descr, "^-\\s*", ""))

# conduct left_join to add the categorization (lo_categorization) to df_rq2), also add the column learning_outcome
combined_df_lo <- combined_df_lo %>%
  left_join(lo_categorization, by = c("learn_descr" = "learning_outcome"), relationship = "many-to-many")

# to lower: cat_1
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = tolower(cat_1))

# select columns from lo_framework (X1, X1_en, X5_en)
lo_framework_ <- lo_framework %>%
  select(X1, X1_en, X5, X5_en)

# remove whitespace at the beginning and end of X5_en, X5, X1, X1_en
lo_framework_ <- lo_framework_ %>%
  mutate(across(everything(), str_trim))

# add english names for the categories from lo_framework, match via cat_1 (df_rq2) and X5_en (lo_framework)
combined_df_lo <- combined_df_lo %>%
  left_join(lo_framework_, by = c("cat_1" = "X5"))

# rename columns (X1 = cat_2, X1_en = cat_2_en, X5_en = cat_1_en)
combined_df_lo <- combined_df_lo %>%
  rename(cat_2 = X1, cat_2_en = X1_en, cat_1_en = X5_en)

# change order of columns (everything, then cat_1, cat_1_en, cat_2, cat_2_en)
combined_df_lo <- combined_df_lo %>%
  select(everything(), cat_1, cat_1_en, cat_2, cat_2_en)

# remove whitespace at the beginning and end of cat_1, cat_1_en, cat_2, cat_2_en in combined_df_lo
combined_df_lo <- combined_df_lo %>%
  mutate(across(c(cat_1, cat_1_en, cat_2, cat_2_en), str_trim))
```

```{r prüfung der zugeordneten Werte, include=FALSE}
# delete duplicates in df_rq2_
combined_df_lo_ <- combined_df_lo %>%
  distinct()

# group for id in df_rq2_, then add column n_id as the number of rows for each id
combined_df_lo_ <- combined_df_lo_ %>%
  group_by(id) %>%
  mutate(n_id = n())
```

```{r leere learn_descr is NA, include=FALSE}
# convert empty learn_descr to NA
combined_df_lo_ <- combined_df_lo_ %>%
  mutate(learn_descr = ifelse(learn_descr == "", NA, learn_descr))

```

```{r, include=FALSE}
# if cat_1 = empty or only contains whitespace, then set cat_1 = NA
combined_df_lo_ <- combined_df_lo_ %>%
  mutate(cat_1 = ifelse(str_detect(cat_1, "^\\s*$"), NA, cat_1))

```


```{r add categories manually, include=FALSE}
combined_df_lo <- combined_df_lo_

# convert learn_descr to lower letters
# df_rq2$learn_descr <- tolower(df_rq2_$learn_descr)
combined_df_lo$cat_1 <- tolower(combined_df_lo$cat_1)

combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(is.na(cat_1), 
                case_when(
                  # Matches cases with only "keine", "nein", "-", ".", whitespace, or an empty string
                  is.na(learn_descr) ~ "keine angabe", 
                  str_detect(learn_descr, paste0(
                    "^(\\s*-\\s*|",
                    "^\\s*-\\s*$|",
                    "\\s*—\\s*|",
                    "\\s*\\.\\s*|",
                    "\\s*|",
                    "\\s*das\\s*|",
                    "\\s*ferien\\s*|",
                    "\\s*./.\\s*|",
                    "\\s*jjj\\s*|",
                    "\\s*ä\\s*|",
                    "\\s*ü\\s*|",
                    "\\s*x\\s*|)$", 
                    "^$", # empty string
                    "^\\s+$"  # whitespace
                    )) ~ "keine angabe",
                  str_detect(learn_descr, paste0(
                    "^(\\s*keine\\s*|",
                    "\\s*nein\\s*|",
                    "\\s*keine.\\s*|",
                    "\\s*kein\\s*|",
                    "\\s*keinr\\s*|",
                    "\\s*kekeine\\s*|",
                    "\\s*0\\s*)$"
                    )) ~ "nichts", 
                  str_detect(learn_descr, paste0(
                  "^(\\s*ja\\s*|",
                    "\\s*s. oben\\s*)$"
                    )) ~ "sonstiges", 
                  TRUE ~ cat_1
                ), cat_1))

# set cat_1 to keine angabe if learn_descr contains "-"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*-\\s*$"), "keine angabe", cat_1))

# set cat_1 to keine angabe if learn_descr contains "."
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*\\.\\s*$"), "keine angabe", cat_1))

# set cat_1 to keine angabe if cat_1 is NA
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(is.na(cat_1), "keine angabe", cat_1))

# set cat_1 to vermutliche falscheingabe if learn_descr only contains a single letter (e.g., "x") or a single letter is repeated (e.g., "xxx")
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*(.)\\1*\\s*$"), "vermutliche falscheingabe", cat_1))

# set cat_1 to keine angabe if learn_descr only contains "./."
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*./.\\s*$"), "keine angabe", cat_1))

# set cat_1 to vermutliche falscheingabe if learn_descr only contains "das"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*das\\s*$"), "vermutliche falscheingabe", cat_1))

# set cat_1 to nichts if learn_descr only contains "ferien"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*ferien\\s*$"), "nichts", cat_1))

# set cat_1 to nichts if learn_descr only contains "elternzeit"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*elternzeit\\s*$"), "nichts", cat_1))

# set cat_1 to nichts if learn_descr only contains "av"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*av\\s*$"), "nichts", cat_1))

# set cat_1 to nichts if learn_descr only contains "abi korrektur"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(str_detect(learn_descr, "^\\s*abi korrektur\\s*$"), "nichts", cat_1))
```

```{r, include=FALSE}
# set cat_1 to keine angabe if learn_descr only contains NA
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(is.na(learn_descr), "keine angabe", cat_1))

# set cat_1 to keine angabe if cat_1 only contains NA
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = ifelse(is.na(cat_1), "keine angabe", cat_1))
```

```{r check which entries have to be checked, include=FALSE, eval=FALSE}
# change cat_1 to NA when cat_1 is empty
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1 = na_if(cat_1, ""), 
         learn_descr = na_if(learn_descr, ""))
  
# Wie viele Zeilen mit NA in cat_1? 

# filter df_rq2 for NA in cat_1
combined_df_lo_na <- combined_df_lo %>%
  filter(is.na(cat_1))

combined_df_lo_NOTna <- combined_df_lo %>%
  filter(!is.na(cat_1))

### Rest, der noch zu kodieren ist #####
df_rq2_NA_tocheck <- df_rq2_na %>% 
  filter(!is.na(learn_descr))

# put column learn_descr from df_rq2_NA_tocheck into dataframe
combined_df_lo_NA_tocheck_ <- combined_df_lo_NA_tocheck %>%
  select(learn_descr, cat_1)

combined_df_lo_NA_tocheck_ <- combined_df_lo_NA_tocheck_ %>%
  ungroup %>%
  select(-id)

# delete duplicates
combined_df_lo_NA_tocheck_unique <- combined_df_lo_NA_tocheck_ %>%
  distinct()

# save as csv but separator = ";"
# write.csv(combined_df_lo_NA_tocheck_unique, "_data/df_rq2_NA_tocheck_unique.csv")

```

```{r, include=FALSE}
# set cat_2_en and cat_1_en to "no response" if cat_1 is "keine angabe", set cat_2 to "keine angabe"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_2 = ifelse(cat_1 == "keine angabe", "keine angabe", cat_2),
         cat_1_en = ifelse(cat_1 == "keine angabe", "no response", cat_1_en),
         cat_2_en = ifelse(cat_1 == "keine angabe", "no response", cat_2_en))

# set cat_2_en and cat_1_en to "nothing" if cat_1 is "nichts", set cat_2 to "nichts"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_2 = ifelse(cat_1 == "nichts", "nichts", cat_2),
         cat_1_en = ifelse(cat_1 == "nichts", "nothing", cat_1_en),
         cat_2_en = ifelse(cat_1 == "nichts", "nothing", cat_2_en))

# set cat_2_en and cat_1_en to "other" if cat_1 is "sonstiges", set cat_2 to "sonstiges"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_2 = ifelse(cat_1 == "sonstiges", "sonstiges", cat_2),
         cat_1_en = ifelse(cat_1 == "sonstiges", "other", cat_1_en),
         cat_2_en = ifelse(cat_1 == "sonstiges", "other", cat_2_en))

# set cat_2_en and cat_1_en to "presumed incorrect entry" if cat_1 is "vermutliche falscheingabe", set cat_2 to "vermutliche falscheingabe"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_2 = ifelse(cat_1 == "vermutliche falscheingabe", "vermutliche falscheingabe", cat_2),
         cat_1_en = ifelse(cat_1 == "vermutliche falscheingabe", "presumed incorrect entry", cat_1_en),
         cat_2_en = ifelse(cat_1 == "vermutliche falscheingabe", "presumed incorrect entry", cat_2_en))

# If cat_1 is "jobunzufriedenheit/frustration", set cat_1_en to "job dissatisfaction / frustration", set cat_2 to "kompetenz", set cat_2_en to "competence"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1_en = ifelse(cat_1 == "jobunzufriedenheit/frustration", "job dissatisfaction / frustration", cat_1_en),
         cat_2 = ifelse(cat_1 == "jobunzufriedenheit/frustration", "kompetenz", cat_2),
         cat_2_en = ifelse(cat_1 == "jobunzufriedenheit/frustration", "competence", cat_2_en))

# if cat_1 is "pausenbewusstsein und ressourcenschonung", set cat_1_en to "Break awareness and resource conservation", set cat_2 to "kompetenz", set cat_2_en to "competence"
combined_df_lo <- combined_df_lo %>%
  mutate(cat_1_en = ifelse(cat_1 == "pausenbewusstsein und ressourcenschonung", "Break awareness and resource conservation", cat_1_en),
         cat_2 = ifelse(cat_1 == "pausenbewusstsein und ressourcenschonung", "kompetenz", cat_2),
         cat_2_en = ifelse(cat_1 == "pausenbewusstsein und ressourcenschonung", "competence", cat_2_en))

combined_df_lo <- combined_df_lo %>%
  filter(cat_1 != "keine angabe" & cat_1 != "nichts" & cat_1 != "vermutliche falscheingabe")

```


```{r, include=FALSE}
df_rq2 <- combined_df_lo

# create a table of cat_1 in df_rq2, also include a total sum
table_cat_1 <- df_rq2 %>%
  group_by(cat_1_en) %>%
  summarize(count = n(), .groups = 'drop') %>%
  arrange(desc(count))

# add sum of all categories
table_cat_1 <- table_cat_1 %>%
  mutate(sum = sum(count))

# add relative frequency in percent
table_cat_1 <- table_cat_1 %>%
  mutate(percentage = count / sum * 100)

# order the table: first order by column count
table_cat_1 <- table_cat_1 %>%
  arrange(desc(count), cat_1_en)

# order by column cat_1_en, value other" comes last
table_cat_1 <- table_cat_1 %>%
  arrange(cat_1_en == "other", .by_group = TRUE)

# select columns from table_cat_1 (cat_1_en, count, percentage)
table_cat_1 <- table_cat_1 %>%
  select(cat_1_en, count, sum, percentage)
```

```{r rq2a kable, echo=FALSE}
table_cat_1 %>%
  kable(
    caption = "Outcomes of Vocational Teachers' Daily Work Activities (RQ2)",
    col.names = c("Activity", "Number of LOs", "Sum", "Percentage")
  )
```

## RQ3: Learning Outcomes across Vocational Teachers' Everyday Work Activities

```{r, include=FALSE}
df_rq3 <- combined_df_lo

# put the data into the long format
df_long <- df_rq3 %>%
  pivot_longer(cols = c(cat_1_en),
               names_to = "category_type", 
               values_to = "category")

# counting the occurrence for every activity and each category
table_rq3 <- df_long %>%
  group_by(act_no, category) %>%
  summarize(count = n(), .groups = 'drop') %>%
  pivot_wider(names_from = category, values_from = count, values_fill = 0)

# sum of the rows (for each activity)
table_rq3 <- table_rq3 %>%
  mutate(act_no = as.character(act_no)) %>%
  mutate(sum = rowSums(select(., -act_no)))

# sum of the columns (for each category)
#####

# Calculate column sums for each learning outcome category
column_sums <- colSums(select(table_rq3, -act_no, -sum), na.rm = TRUE)

# Create a tibble for the totals row
total_row <- tibble(
  act_no = "Total",
  !!!column_sums  # Using the `!!!` operator to spread the sums into columns
)

# Bind the totals row to the original table
table_rq3 <- table_rq3 %>%
  bind_rows(total_row)

table_rq3 <- table_rq3
# rm(table_rq3)
# rm(table_rq2b_with_totals)
rm(total_row)

```

```{r, include=FALSE}
# transpone table_rq2b
table_rq3_ <- as.data.frame(t(table_rq3))

table_rq3_ <- tibble::rownames_to_column(table_rq3_)

table_rq3 <- table_rq3_
colnames(table_rq3) <- table_rq3[1, ]  # Setzt die erste Zeile als Spaltennamen
table_rq3 <- table_rq3[-1, ]  # Entfernt die erste Zeile aus dem Dataframe
rownames(table_rq3) <- NULL  # Setzt die Zeilennummern zurück

# rename first column into activity
table_rq3 <- table_rq3 %>%
  rename(activity = act_no)

```

```{r divide the tables, include=FALSE}
# divide the table into two tables: one with activity from 1 to 15 and one with 16 to 29 as well as Total
table_rq3_1 <- table_rq3 %>%
  select("activity", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15")

table_rq3_2 <- table_rq3 %>%
  select("activity", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "Total")
```

```{r rq3_1 kable, echo=FALSE}
table_rq3_1 %>%
  kable(
    caption = "Learning Categories across Vocational Teachers' Daily Work Activities (RQ2 (1))", col.names = c("LO category", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15")
  )
```

```{r rq3_2 kable, echo=FALSE}
table_rq3_2 %>%
  kable(
    caption = "Learning Categories across Vocational Teachers' Daily Work Activities (RQ2 (2))"
  )
```

## RQ4: Relation of extent of perceived learning to coded learning outcomes

```{r, include=FALSE}
df_rq4 <- combined_df_lo

# create a table cate_1_pcl of cat_1 and also include pc_learn from df_rq2
table_rq4_cat_1 <- df_rq4 %>%
  group_by(cat_1_en) %>%
  summarize(count = n(), 
            pc_learn_m = mean(pc_learn, na.rm = TRUE), 
            pc_learn_sd = sd(pc_learn, na.rm = TRUE),
            pc_learn_md = median(pc_learn, na.rm = TRUE),
            .groups = 'drop') %>%
  arrange(desc(count))
```

```{r, include=FALSE}
# create a table cate_1_pcl of cat_2 in also include pc_learn from df_rq2
table_rq4_cat_2 <- df_rq4 %>%
  group_by(cat_2_en) %>%
  summarize(count = n(), 
            pc_learn_m = mean(pc_learn, na.rm = TRUE), 
            pc_learn_sd = sd(pc_learn, na.rm = TRUE), 
            pc_learn_md = median(pc_learn, na.rm = TRUE),
            .groups = 'drop') %>%
  arrange(desc(count))

# order the table: other comes last in column cat_2_en
table_rq4_cat_2 <- table_rq4_cat_2 %>%
  arrange(cat_2_en == "other", .by_group = TRUE)
```

```{r, include=FALSE}
# count the occurrence of competence in df_rq2 (cat_2) 
table_rq4_cat_2b <- df_rq4 %>%
  group_by(cat_2_en) %>%
  summarize(count = n(), .groups = 'drop') %>%
  arrange(desc(count))
```

```{r rq4 cat_1 kable, echo=FALSE}
table_rq4_cat_1 %>%
  kable(
    caption = "Relation of Extent of Perceived Learning to Coded Learning Outcomes (RQ4)", col.names = c("LO category", "Number of LOs", "M", "SD", "Mdn")
  )
```

```{r rq4 cat_2 kable, echo=FALSE}
table_rq4_cat_2 %>%
  kable(
    caption = "Relation of Extent of Perceived Learning to Coded Learning Outcomes (RQ4)", col.names = c("LO category", "Number of LOs", "M", "SD", "Mdn")
  )
```


## RQ5: Predicting Vocational Teachers' Informal Learning Using Stress and Coping during their Daily Work Activities (as stated in Karasek's Learning Hypothesis)

-   interaction effect

```{r filter data & prepare them, include=FALSE}
df_rq3 <- combined_df
df_rq3$act_no <- as.factor(df_rq3$act_no)

# standardize all variables

# df_rq3$pc_learn_z <- standardize(df_rq3$pc_learn)
df_rq3$stress_z <- standardize(df_rq3$stress)
df_rq3$coping_z <- standardize(df_rq3$coping)


# add dummy variables for act #####
df_rq3 <- dummy_cols(df_rq3, select_columns = "act_no")

```

```{r test all assumptions, include=FALSE}
# multicollinearity?!
# especially with the interaction term ... 
```

```{r correlations, include = FALSE}
# cor_tab <- cor(subset(variant1, select = c(task_routine:proc_learn)))

rq3_subset_cor <- subset(df_rq3, select = c(sex:jobscope, stress:pc_learn, n_entry, stress_z, coping_z))

# maybe add mean and sd

cor_tab_ <- rq3_subset_cor %>%
  # select(c(group_mlm:proc_learn)) %>%
  correlate() %>%
  shave(upper = TRUE) %>%
  fashion(decimals = 2, na_print = "—") 

cor_tab_$term <- paste(seq_len(nrow(cor_tab_)), ". ", cor_tab_$term, sep = "")
```

```{r rq3 corr_table_kable, echo=FALSE}
cor_tab_ %>%
  kable(
    caption = "Correlations between Variables RQ3",
    col.names = c("Measure", "1", "2", "3", "4", "5", "6", "7", "8", "9")
  )
```

```{r rq3 model 1, include=FALSE}
rq3_model1 <- lmerTest::lmer(data = df_rq3, pc_learn ~ 1 + (1|code), REML = T) 

# summary(rq3_model1)
```

```{r rq3 model 1 ICC, echo=FALSE}
# icc calculation
# icc(rq2_model1)
kable(table(round(icc(rq3_model1), 4)), caption = "ICC RQ3 (REML)")
```

```{r rq3 model 1 REML_F, include=FALSE}
rq3_model1 <- lmerTest::lmer(data = df_rq3, pc_learn ~ 1 + (1|code), REML = F) 
```

```{r rq3 model 2, include=FALSE}
# issue: act_no 29 not available

rq3_model2 <- lmerTest::lmer(data = df_rq3, pc_learn ~  sex + age + jobscope + stress_z + coping_z + stress_z*coping_z + n_entry + 
                               act_no_1 +  act_no_2 + 
                               act_no_3 +  act_no_4 +
                               act_no_5 +  act_no_6 + 
                               act_no_7 +  act_no_8 + 
                               act_no_9 +  act_no_10 + 
                               act_no_11 + act_no_12 + 
                               act_no_13 + act_no_14 + 
                               act_no_15 + act_no_16 + 
                               act_no_17 + act_no_18 + 
                               act_no_19 + act_no_20 +
                               act_no_21 + act_no_22 +
                               act_no_23 + act_no_24 +
                               act_no_25 + act_no_26 +
                               act_no_27 + act_no_28 + #act_no_29 + 
                               (1|code), REML = F) # + time + activity dummy variables

summary(rq3_model2)
```

```{r rq3 results table, echo=FALSE}
rq3_results_table <- modelsummary::msummary(list("Model 1" = rq3_model1, 
                                                 "Model 2" = rq3_model2), gof_omit = "ICC", stars = T, title = "Summary Multilevel Model RQ3", output = 'kableExtra', metrics = "all", statistic = c("std.error", "p.value", "conf.int"))

rq3_results_table %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")
```

```{r rq3 kable, echo=FALSE}
# kable(rq3_model2, digits = 2, caption = "MLM of Informal Learning during Teachers' Work Activities ")
```

# Conclusion

\newpage

# Data availability statement

The anonymized data are available on Mendeley Data (<https://www.elsevier.com/researcher/author/tools-and-resources/research-data>) under the following link: ...\

# References

::: {#refs custom-style="Bibliography"}
:::

\newpage

# Appendix

## Possible Journals {.unnumbered}

Teaching and Teacher Education (IF: 4.0),\
[https://doi.org/10.1016/S0742-051X(02)00101-4](https://doi.org/10.1016/S0742-051X(02)00101-4 "Persistent link using digital object identifier") was also published here

Regelungen/Hinweise:

-   Abstract: 100 words, 3 - 6 keywords

-   Report: 5.000-9.000 words

Ansonsten:

-   Human Resource Development International (IF: 3.8)

    -   <https://doi.org/10.1080/13678860010004123> was also published here

-   Journal of Workplace Learning (IF: )

-   Vocations and Learning (IF: 1.9)

-   Learning Environments Research (IF: 2.7)

-   Technology, Knowledge and Learning (IF: 3.0) - not that fitting...

-   Empirical Research in Vocational Education and Training (IF: 1.6)

-   Learning and Instruction (IF: 4.7) - not that fitting...


```{r, eval=FALSE, include=FALSE}
# create sample_table from df_rq2, delete all duplicates, only keep columns code, sex, age, jobscope
sample_table <- df_rq2 %>%
  select(code, sex, age, jobscope) %>%
  distinct()

sample_table_test <- sample_table %>%
  group_by(code) %>%
  mutate(n_code = n())
```

```{r, eval=FALSE, include=FALSE}
# check df_rq2 for values != (keine angabe ODER nichts ODER vermutliche falscheingabe) in learn_descr
df_rq2_test <- df_rq2 %>%
  filter(!str_detect(cat_1, "keine angabe|nichts|vermutliche falscheingabe"))
```


```{r, eval=FALSE, include=FALSE}
welcome_table <- welcome_raw %>%
  select(Code, Geschlecht, Alter) %>%
  distinct()
```

